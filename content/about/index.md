---
title: "About Me"
date: 2025-06-30T00:00:00-00:00
draft: false
---


{{< social-icons >}}


## Career Overview

**Applied Scientist at Amazon Search (Rufus)**  
*Mar. 2023 – Present*  
- Contributed to Amazon Rufus, an LLM-powered shopping assistant, by applying scientific insights to develop scalable systems for IFT training data augmentation and automating key evaluation processes, significantly enhancing model development, training data quality, and feature launches.

- Led the development of an innovative product insight feature on Amazon’s shopping website, enhancing the customer experience by simplifying product discovery. Implemented an LLM-powered system that generates concise product summaries, highlighting unique differentiators compared to competing products in search results. This innovation led to an annualized OPS impact of over $100M.

**Applied Scientist at Amazon AWS AI Labs**  
*Jun. 2022 – Mar. 2023*  
- Worked in the Lex ASR Science Team, developing a chatbot tailored to customer needs. Focused on personalization techniques to enhance user experience rather than general ASR improvements. Key projects included improving ASR performance by integrating pre-trained language models for first-pass and second-pass rescoring.

**NLP Researcher at ByteDance AI Lab, Shanghai, China**  
*Dec. 2018 – Jul. 2021*  
- Worked in the Machine Translation Team on '[Volctrans](https://translate.volcengine.com/)', a multilingual machine translation service. Focused on research and development of multilingual translation techniques, as well as optimizing and deploying models for various translation directions. Demonstrated strong teamwork and collaboration skills.


---

## Research

[**Contrastive Learning for Many-to-many Multilingual Neural Machine Translation, ACL 2021 long**](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://aclanthology.org/2021.acl-long.21/&ved=2ahUKEwiapJmW0LaOAxXeMdAFHcqkLWMQFnoECA4QAQ&usg=AOvVaw0bdW31Aj5TUOZns31Gynmp)

_Authors: Xiao Pan, [Mingxuan Wang](https://mingxuan.github.io/), Liwei Wu, [Lei Li](https://lileicc.github.io/)_  
- Developed as the main contributor (90%+ contribution) an all-in-one multilingual machine translation model using contrastive learning. It supports 100 languages and achieves consistent improvements over the strong multilingual Transformer baseline. For non-English zero-shot directions, mRASP2 even achieves an improvement of average 10+ BLEU compared with the baseline (implemented using Fairseq, open-sourced at [https://github.com/PANXiao1994/mRASP2](https://github.com/PANXiao1994/mRASP2)).
- Trained and deployed a mRASP2 model using large-scale in-house corpora and deployed to the service "Volctrans".
- Handled the preprocessing process of large-scale corpora using shell script and distributed toolkits.

[**Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information, EMNLP 2020 long**](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://aclanthology.org/2020.emnlp-main.210/&ved=2ahUKEwiIsNmv0LaOAxXeJNAFHXbfIfsQFnoECCkQAQ&usg=AOvVaw1enorPlLOd0tP2fAQA3D4D)

_Authors: Zehui Lin*, Xiao Pan*, [Mingxuan Wang](https://mingxuan.github.io/), Xipeng Qiu, Jiangtao Feng, Hao Zhou, [Lei Li](https://lileicc.github.io/) (*: equal contribution)_  
- Developed a large-scale pre-training model for machine translation. First to propose "Exotic Full" scenario, where source and target languages are not in training corpora (implemented using Fairseq, open-sourced at [https://github.com/linzehui/mRASP](https://github.com/linzehui/mRASP)).
- Improved the MT performance of extremely low resource directions (<100k) by an average of 20+ BLEU; especially, for "Exotic Full" scenario, with only 12K parallel sentence pairs for Dutch—Portuguese, mRASP still reaches 10+ BLEU.
- Trained and deployed a pre-trained model using large-scale in-house corpora, improved production model performance and the training efficiency.

---

## Education

**Paris-Saclay University, Paris, France**  
*Master-2 in Applied Mathematics*  
Sep. 2017 – Oct. 2018

**Télécom ParisTech, Paris, France**  
*Master's Degree – Major in Data Science and Machine Learning*  
Sep. 2016 – Oct. 2018

**Tongji University, Shanghai, China**  
*Bachelor's Degree – Major in Communication Engineering*  
Sep. 2012 – Jul. 2016 